{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "069eec16-9408-4b13-a26f-f85ab2d0bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c497ebb6-69da-4be6-9a04-1f1e61f80af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_scorer(preprocessor):\n",
    "    \"\"\"\n",
    "    Optimized scorer function with parallel processing\n",
    "    \"\"\"\n",
    "    def scorer(model_name, model):\n",
    "        output = []\n",
    "        output.append(model_name)\n",
    "        \n",
    "        # Set n_jobs for models that support it\n",
    "        if hasattr(model, 'n_jobs'):\n",
    "            model.set_params(n_jobs=-1)\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "        \n",
    "        # K-fold cross-validation with parallel jobs\n",
    "        kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(\n",
    "            pipeline, X, y_transformed, \n",
    "            cv=kfold, \n",
    "            scoring='r2',\n",
    "            n_jobs=-1  # Parallel cross-validation\n",
    "        )\n",
    "        \n",
    "        output.append(scores.mean())\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_transformed, test_size=0.2, random_state=42\n",
    "        )\n",
    "        print(\"Training the pipeline\")\n",
    "       \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        print(\"predicting the pipeline\")\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_pred = np.expm1(y_pred)\n",
    "        print(\"appending the solution of pipeline\")\n",
    "        output.append(mean_absolute_error(np.expm1(y_test), y_pred))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    return scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4faed6fc-c03b-401e-ae67-2111f2527f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_models():\n",
    "    \"\"\"\n",
    "    Create models with optimized parameters for faster training\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'linear_reg': LinearRegression(),\n",
    "        'ridge': Ridge(),\n",
    "        'LASSO': Lasso(),\n",
    "        'svr': SVR(),  # SVR is slow, consider reducing C or using kernel='linear'\n",
    "        'decision tree': DecisionTreeRegressor(max_depth=20),  # Limit depth\n",
    "        \n",
    "        # Optimized Random Forest\n",
    "        'random forest': RandomForestRegressor(\n",
    "            n_estimators=150,  # Reduced from default\n",
    "            max_depth=20,      # Limit depth\n",
    "            min_samples_split=10,  # Increase for speed\n",
    "            min_samples_leaf=4,    # Increase for speed\n",
    "            n_jobs=-1,         # Parallel processing\n",
    "            random_state=42\n",
    "        ),\n",
    "        \n",
    "        # Optimized Extra Trees\n",
    "        'extra trees': ExtraTreesRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=20,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=4,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ),\n",
    "        \n",
    "        # Optimized Gradient Boosting\n",
    "        'gradient boosting': GradientBoostingRegressor(\n",
    "         \n",
    "        ),\n",
    "        \n",
    "        'adaboost': AdaBoostRegressor(\n",
    "            n_estimators=50,   # Reduced from default\n",
    "            learning_rate=1.0,\n",
    "            random_state=42\n",
    "        ),\n",
    "        \n",
    "        'mlp': MLPRegressor(\n",
    "            hidden_layer_sizes=(100,),  # Simpler architecture\n",
    "            max_iter=200,      # Reduced iterations\n",
    "            early_stopping=True,  # Stop early if no improvement\n",
    "            random_state=42\n",
    "        ),\n",
    "        \n",
    "        # Optimized XGBoost\n",
    "        'xgboost': XGBRegressor(\n",
    "         \n",
    "        ),\n",
    "        \n",
    "        # Optimized LightGBM (fastest gradient boosting)\n",
    "        'lightgbm': lgb.LGBMRegressor(\n",
    "            \n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            verbose=-1  # Suppress warnings\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf4f60c3-f233-4735-beaf-16a2ceb48d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# OPTIMIZATION 3: Optimized preprocessing\n",
    "# ============================================\n",
    "\n",
    "def create_optimized_preprocessor(columns_to_encode):\n",
    "    \"\"\"\n",
    "    Create preprocessor with handle_unknown for OrdinalEncoder\n",
    "    \"\"\"\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), \n",
    "             ['bedRoom', 'bathroom', 'built_up_area', 'servant room', 'store room']),\n",
    "            ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), \n",
    "             columns_to_encode),\n",
    "            ('cat1', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), \n",
    "             ['sector'])\n",
    "        ], \n",
    "        remainder='passthrough',\n",
    "        n_jobs=-1  # Parallel preprocessing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94a21a8a-dad1-42fe-a498-17201de1d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_model_selection(X, y_transformed, preprocessor):\n",
    "    \"\"\"\n",
    "    Quick model selection - test only fast models first\n",
    "    \"\"\"\n",
    "    print(\"Phase 1: Testing fast models...\")\n",
    "    \n",
    "    fast_models = {\n",
    "        'linear_reg': LinearRegression(),\n",
    "        'ridge': Ridge(),\n",
    "        'LASSO': Lasso(),\n",
    "        'decision tree': DecisionTreeRegressor(max_depth=20),\n",
    "        'xgboost': XGBRegressor(n_estimators=100, max_depth=6, n_jobs=-1, random_state=42),\n",
    "        'lightgbm': lgb.LGBMRegressor(n_estimators=100, max_depth=6, n_jobs=-1, \n",
    "                                      random_state=42, verbose=-1)\n",
    "    }\n",
    "    \n",
    "    scorer = create_optimized_scorer(preprocessor)\n",
    "    fast_results = []\n",
    "    \n",
    "    for model_name, model in fast_models.items():\n",
    "        print(f\"  Training {model_name}...\")\n",
    "        fast_results.append(scorer(model_name, model))\n",
    "    \n",
    "    fast_df = pd.DataFrame(fast_results, columns=['name', 'r2', 'mae'])\n",
    "    print(\"\\nFast models results:\")\n",
    "    print(fast_df.sort_values(['mae']))\n",
    "    \n",
    "    return fast_df\n",
    "\n",
    "\n",
    "def full_model_selection(X, y_transformed, preprocessor):\n",
    "    \"\"\"\n",
    "    Full model selection including slower models\n",
    "    \"\"\"\n",
    "    print(\"\\nPhase 2: Testing all models...\")\n",
    "    \n",
    "    all_models = create_optimized_models()\n",
    "    scorer = create_optimized_scorer(preprocessor)\n",
    "    all_results = []\n",
    "    \n",
    "    for model_name, model in all_models.items():\n",
    "        print(f\"  Training {model_name}...\")\n",
    "        all_results.append(scorer(model_name, model))\n",
    "    \n",
    "    full_df = pd.DataFrame(all_results, columns=['name', 'r2', 'mae'])\n",
    "    print(\"\\nAll models results:\")\n",
    "    print(full_df.sort_values(['mae']))\n",
    "    \n",
    "    return full_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5d4a375-8a47-400f-a8df-f48f622e013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_test_on_sample(X, y_transformed, preprocessor, sample_size=0.3):\n",
    "    \"\"\"\n",
    "    Quick test on a sample of data to identify best models\n",
    "    \"\"\"\n",
    "    print(f\"Quick test on {int(sample_size*100)}% sample...\")\n",
    "    \n",
    "    # Sample data\n",
    "    X_sample = X.sample(frac=sample_size, random_state=42)\n",
    "    y_sample = y_transformed[X_sample.index]\n",
    "    \n",
    "    models = create_optimized_models()\n",
    "    scorer = create_optimized_scorer(preprocessor)\n",
    "    \n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"  Testing {model_name}...\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "        \n",
    "        # Single train-test split (faster than cross-validation)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_sample, y_sample, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        score = pipeline.score(X_test, y_test)\n",
    "        \n",
    "        y_pred = np.expm1(pipeline.predict(X_test))\n",
    "        mae = mean_absolute_error(np.expm1(y_test), y_pred)\n",
    "        \n",
    "        results.append([model_name, score, mae])\n",
    "    \n",
    "    sample_df = pd.DataFrame(results, columns=['name', 'r2', 'mae'])\n",
    "    print(\"\\nQuick sample results:\")\n",
    "    print(sample_df.sort_values(['mae']))\n",
    "    \n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a188d921-9978-4c3b-bcdc-fac158daa7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['property_type', 'balcony', 'agePossession', \n",
    "                     'furnishing_type', 'luxury_category', 'floor_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74b1ea97-6b7d-4e89-bd3f-bf71861e779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('concatenated_properties_for prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20ccb39b-a7ad-4b5b-b242-a0f1fa1c2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 -> unfurnished\n",
    "# 1 -> semifurnished\n",
    "# 2 -> furnished\n",
    "df['furnishing_type'] = df['furnishing_type'].replace({0.0:'unfurnished',1.0:'semifurnished',2.0:'furnished'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c11e2964-1433-4448-9438-5b81a25a8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['price'])\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "edd465af-443c-41c5-9b6f-a2de1ed15f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the log1p transformation to the target variable\n",
    "y_transformed = np.log1p(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3db4562-7a3d-4cea-ae3f-7a0fd2bae369",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = create_optimized_preprocessor(columns_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8423362c-d29a-46bb-bff0-4b8cef4bc979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick test on 30% sample...\n",
      "  Testing linear_reg...\n",
      "  Testing ridge...\n",
      "  Testing LASSO...\n",
      "  Testing svr...\n",
      "  Testing decision tree...\n",
      "  Testing random forest...\n",
      "  Testing extra trees...\n",
      "  Testing gradient boosting...\n",
      "  Testing adaboost...\n",
      "  Testing mlp...\n",
      "  Testing xgboost...\n",
      "  Testing lightgbm...\n",
      "\n",
      "Quick sample results:\n",
      "                 name        r2       mae\n",
      "10            xgboost  0.810507  0.760677\n",
      "7   gradient boosting  0.779517  0.849169\n",
      "3                 svr  0.779563  0.865169\n",
      "9                 mlp  0.750291  0.878099\n",
      "6         extra trees  0.740019  0.903042\n",
      "5       random forest  0.732514  0.931570\n",
      "11           lightgbm  0.719073  0.980582\n",
      "4       decision tree  0.672883  1.084246\n",
      "0          linear_reg  0.679700  1.114385\n",
      "1               ridge  0.694364  1.153454\n",
      "8            adaboost  0.540370  1.287900\n",
      "2               LASSO -0.000271  1.705427\n"
     ]
    }
   ],
   "source": [
    "sample_results = quick_test_on_sample(X, y_transformed, preprocessor, sample_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "027f2c2e-54df-404e-ad62-09bb8c7a94ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Testing fast models...\n",
      "  Training linear_reg...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training ridge...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training LASSO...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training decision tree...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training xgboost...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training lightgbm...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "\n",
      "Fast models results:\n",
      "            name        r2       mae\n",
      "4        xgboost  0.826413  0.746002\n",
      "5       lightgbm  0.812146  0.814708\n",
      "3  decision tree  0.710579  0.858151\n",
      "1          ridge  0.753087  0.964438\n",
      "0     linear_reg  0.743327  0.969953\n",
      "2          LASSO -0.002390  1.692700\n"
     ]
    }
   ],
   "source": [
    "fast_results = quick_model_selection(X, y_transformed, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee761f25-dbe8-418d-a068-4da02ccc82f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 2: Testing all models...\n",
      "  Training linear_reg...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training ridge...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training LASSO...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training svr...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training decision tree...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training random forest...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training extra trees...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training gradient boosting...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training adaboost...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training mlp...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training xgboost...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "  Training lightgbm...\n",
      "Training the pipeline\n",
      "predicting the pipeline\n",
      "appending the solution of pipeline\n",
      "\n",
      "All models results:\n",
      "                 name        r2       mae\n",
      "10            xgboost  0.826413  0.746002\n",
      "3                 svr  0.821351  0.769825\n",
      "11           lightgbm  0.825231  0.773370\n",
      "9                 mlp  0.809526  0.803788\n",
      "6         extra trees  0.801277  0.805419\n",
      "5       random forest  0.777550  0.834194\n",
      "7   gradient boosting  0.791695  0.851501\n",
      "4       decision tree  0.707853  0.873700\n",
      "1               ridge  0.753087  0.964438\n",
      "0          linear_reg  0.743327  0.969953\n",
      "8            adaboost  0.495574  1.232783\n",
      "2               LASSO -0.002390  1.692700\n"
     ]
    }
   ],
   "source": [
    "full_results = full_model_selection(X, y_transformed, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42f91ac4-0ad4-4b47-aa6d-d635c7f0d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_n_estimators_impact(X, y_transformed, preprocessor, \n",
    "                                 estimator_range=[50, 100, 200, 300, 500]):\n",
    "    \"\"\"\n",
    "    Analyze the impact of number of trees on performance and training time\n",
    "    Shows diminishing returns of adding more trees\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    print(\"Analyzing n_estimators impact on RandomForest...\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    results = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_transformed, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    for n_est in estimator_range:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=20,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "        \n",
    "        # Train and evaluate\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Get scores\n",
    "        r2_score = pipeline.score(X_test, y_test)\n",
    "        y_pred = np.expm1(pipeline.predict(X_test))\n",
    "        mae = mean_absolute_error(np.expm1(y_test), y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'n_estimators': n_est,\n",
    "            'r2_score': r2_score,\n",
    "            'mae': mae,\n",
    "            'train_time_sec': train_time,\n",
    "            'improvement_from_previous': 0\n",
    "        })\n",
    "        \n",
    "        print(f\"n_estimators={n_est:3d} | RÂ²={r2_score:.4f} | MAE={mae:.4f} | Time={train_time:.1f}s\")\n",
    "    \n",
    "    # Calculate improvements\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['improvement_from_previous'] = results_df['r2_score'].diff()\n",
    "    results_df['time_increase'] = results_df['train_time_sec'].diff()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ANALYSIS:\")\n",
    "    print(\"=\"*70)\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Find optimal point (best performance/time ratio)\n",
    "    results_df['efficiency'] = results_df['r2_score'] / results_df['train_time_sec']\n",
    "    optimal_idx = results_df['efficiency'].idxmax()\n",
    "    \n",
    "    print(f\"\\nMost efficient configuration: n_estimators={results_df.iloc[optimal_idx]['n_estimators']:.0f}\")\n",
    "    print(f\"RÂ² Score: {results_df.iloc[optimal_idx]['r2_score']:.4f}\")\n",
    "    print(f\"Training Time: {results_df.iloc[optimal_idx]['train_time_sec']:.1f}s\")\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df006e6b-6f79-4805-aee0-e7b0859a11bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing n_estimators impact on RandomForest...\n",
      "----------------------------------------------------------------------\n",
      "n_estimators= 50 | RÂ²=0.8042 | MAE=0.7546 | Time=2.3s\n",
      "n_estimators=100 | RÂ²=0.8027 | MAE=0.7565 | Time=4.1s\n",
      "n_estimators=200 | RÂ²=0.8033 | MAE=0.7540 | Time=8.6s\n",
      "n_estimators=300 | RÂ²=0.8030 | MAE=0.7539 | Time=12.8s\n",
      "n_estimators=500 | RÂ²=0.8025 | MAE=0.7543 | Time=22.7s\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS:\n",
      "======================================================================\n",
      " n_estimators  r2_score      mae  train_time_sec  improvement_from_previous  time_increase\n",
      "           50  0.804226 0.754554        2.338709                        NaN            NaN\n",
      "          100  0.802676 0.756504        4.133760                  -0.001551       1.795052\n",
      "          200  0.803317 0.754034        8.592401                   0.000641       4.458640\n",
      "          300  0.803048 0.753865       12.811828                  -0.000269       4.219427\n",
      "          500  0.802476 0.754275       22.668892                  -0.000572       9.857064\n",
      "\n",
      "Most efficient configuration: n_estimators=50\n",
      "RÂ² Score: 0.8042\n",
      "Training Time: 2.3s\n"
     ]
    }
   ],
   "source": [
    "results_df = analyze_n_estimresults_df = analyze_n_estimators_impact(\n",
    "    X, y_transformed, preprocessor, \n",
    "    estimator_range=[50, 100, 200, 300, 500]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2078cd0-e1c1-43ad-adb7-c18cb3ecf68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_complexity(X, y_transformed, preprocessor):\n",
    "    \"\"\"\n",
    "    Find optimal model complexity through learning curves\n",
    "    Shows when model stops improving with more complexity\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import learning_curve\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    print(\"Generating learning curves...\")\n",
    "    \n",
    "    # Test different model complexities\n",
    "    configs = [\n",
    "        ('RF-50 trees', RandomForestRegressor(n_estimators=50, n_jobs=-1, random_state=42)),\n",
    "        ('RF-100 trees', RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)),\n",
    "        ('RF-200 trees', RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=42)),\n",
    "        ('RF-500 trees (default)', RandomForestRegressor(n_estimators=500, n_jobs=-1, random_state=42)),\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for name, model in configs:\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "        \n",
    "        # Use smaller cv for speed\n",
    "        train_sizes, train_scores, val_scores = learning_curve(\n",
    "            pipeline, X, y_transformed,\n",
    "            cv=3,  # Reduced for speed\n",
    "            n_jobs=-1,\n",
    "            train_sizes=[0.3, 0.6, 0.8, 1.0],\n",
    "            scoring='r2'\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'name': name,\n",
    "            'train_score_mean': train_scores.mean(axis=1)[-1],\n",
    "            'val_score_mean': val_scores.mean(axis=1)[-1],\n",
    "            'val_score_std': val_scores.std(axis=1)[-1]\n",
    "        })\n",
    "        \n",
    "        print(f\"{name:25s} | Val RÂ²: {val_scores.mean(axis=1)[-1]:.4f} Â± {val_scores.std(axis=1)[-1]:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6854b85-da42-45b6-b0ee-e4210c6c8076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating learning curves...\n",
      "RF-50 trees               | Val RÂ²: 0.7422 Â± 0.1267\n",
      "RF-100 trees              | Val RÂ²: 0.7434 Â± 0.1260\n",
      "RF-200 trees              | Val RÂ²: 0.7436 Â± 0.1258\n",
      "RF-500 trees (default)    | Val RÂ²: 0.7444 Â± 0.1267\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train_score_mean</th>\n",
       "      <th>val_score_mean</th>\n",
       "      <th>val_score_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF-50 trees</td>\n",
       "      <td>0.969077</td>\n",
       "      <td>0.742218</td>\n",
       "      <td>0.126722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF-100 trees</td>\n",
       "      <td>0.969974</td>\n",
       "      <td>0.743433</td>\n",
       "      <td>0.125967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF-200 trees</td>\n",
       "      <td>0.970822</td>\n",
       "      <td>0.743553</td>\n",
       "      <td>0.125831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF-500 trees (default)</td>\n",
       "      <td>0.971042</td>\n",
       "      <td>0.744393</td>\n",
       "      <td>0.126673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name  train_score_mean  val_score_mean  val_score_std\n",
       "0             RF-50 trees          0.969077        0.742218       0.126722\n",
       "1            RF-100 trees          0.969974        0.743433       0.125967\n",
       "2            RF-200 trees          0.970822        0.743553       0.125831\n",
       "3  RF-500 trees (default)          0.971042        0.744393       0.126673"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_optimal_complexity(X, y_transformed, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5697619f-6fe6-4364-8219-08869afc9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_xgboost_randomized(X, y_transformed, preprocessor, n_iter=50):\n",
    "    \"\"\"\n",
    "    Randomized search for XGBoost - faster than GridSearch\n",
    "    Tests random combinations of parameters\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"TUNING XGBOOST - Randomized Search\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Define parameter distributions\n",
    "    param_distributions = {\n",
    "        'regressor__n_estimators': randint(50, 200),  # Random int between 50-200\n",
    "        'regressor__max_depth': randint(3, 10),       # Depth: 3-10\n",
    "        'regressor__learning_rate': uniform(0.01, 0.29),  # LR: 0.01-0.30\n",
    "        'regressor__subsample': uniform(0.6, 0.4),    # Subsample: 0.6-1.0\n",
    "        'regressor__colsample_bytree': uniform(0.6, 0.4),  # Col sample: 0.6-1.0\n",
    "        'regressor__min_child_weight': randint(1, 10),\n",
    "        'regressor__gamma': uniform(0, 0.5),\n",
    "        'regressor__reg_alpha': uniform(0, 1),  # L1 regularization\n",
    "        'regressor__reg_lambda': uniform(0, 1)  # L2 regularization\n",
    "    }\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', XGBRegressor(n_jobs=-1, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Randomized search\n",
    "    random_search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,  # Number of random combinations to try\n",
    "        cv=5,  # 5-fold CV (faster than 10)\n",
    "        scoring='neg_mean_absolute_error',  # Optimize for MAE\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTesting {n_iter} random parameter combinations...\")\n",
    "    print(\"This will take approximately 5-15 minutes...\\n\")\n",
    "    \n",
    "    random_search.fit(X, y_transformed)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"XGBOOST TUNING RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nBest Score (MAE): {-random_search.best_score_:.4f}\")\n",
    "    print(f\"\\nBest Parameters:\")\n",
    "    for param, value in random_search.best_params_.items():\n",
    "        print(f\"  {param.replace('regressor__', '')}: {value}\")\n",
    "    \n",
    "    # Show top 5 configurations\n",
    "    results_df = pd.DataFrame(random_search.cv_results_)\n",
    "    results_df['mean_test_mae'] = -results_df['mean_test_score']\n",
    "    top_5 = results_df.nsmallest(5, 'mean_test_mae')[\n",
    "        ['mean_test_mae', 'std_test_score', 'mean_fit_time', 'params']\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTop 5 Configurations:\")\n",
    "    print(top_5.to_string(index=False))\n",
    "    \n",
    "    return random_search.best_estimator_, random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55e15233-0892-48d9-8c01-12fd42ebe119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lightgbm_randomized(X, y_transformed, preprocessor, n_iter=50):\n",
    "    \"\"\"\n",
    "    Randomized search for LightGBM\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"TUNING LIGHTGBM - Randomized Search\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    param_distributions = {\n",
    "        'regressor__n_estimators': randint(50, 200),\n",
    "        'regressor__max_depth': randint(3, 15),\n",
    "        'regressor__learning_rate': uniform(0.01, 0.29),\n",
    "        'regressor__num_leaves': randint(20, 150),\n",
    "        'regressor__subsample': uniform(0.6, 0.4),\n",
    "        'regressor__colsample_bytree': uniform(0.6, 0.4),\n",
    "        'regressor__min_child_samples': randint(10, 50),\n",
    "        'regressor__reg_alpha': uniform(0, 1),\n",
    "        'regressor__reg_lambda': uniform(0, 1)\n",
    "    }\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', lgb.LGBMRegressor(n_jobs=-1, random_state=42, verbose=-1))\n",
    "    ])\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTesting {n_iter} random parameter combinations...\")\n",
    "    print(\"This will take approximately 3-10 minutes...\\n\")\n",
    "    \n",
    "    random_search.fit(X, y_transformed)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LIGHTGBM TUNING RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nBest Score (MAE): {-random_search.best_score_:.4f}\")\n",
    "    print(f\"\\nBest Parameters:\")\n",
    "    for param, value in random_search.best_params_.items():\n",
    "        print(f\"  {param.replace('regressor__', '')}: {value}\")\n",
    "    \n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f69e6d6e-ac21-4dac-a2d5-8f5c2ada8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_final_model(best_model, X, y_transformed):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the tuned model\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL MODEL EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Cross-validation scores\n",
    "    cv_scores_r2 = cross_val_score(\n",
    "        best_model, X, y_transformed,\n",
    "        cv=10,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv_scores_mae = cross_val_score(\n",
    "        best_model, X, y_transformed,\n",
    "        cv=10,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nCross-Validation Results (10-fold):\")\n",
    "    print(f\"  RÂ² Score:  {cv_scores_r2.mean():.4f} Â± {cv_scores_r2.std():.4f}\")\n",
    "    print(f\"  MAE:       {-cv_scores_mae.mean():.4f} Â± {cv_scores_mae.std():.4f}\")\n",
    "    \n",
    "    # Get predictions for all data\n",
    "    y_pred_transformed = cross_val_predict(best_model, X, y_transformed, cv=10)\n",
    "    \n",
    "    # Transform back to original scale\n",
    "    y_pred = np.expm1(y_pred_transformed)\n",
    "    y_actual = np.expm1(y_transformed)\n",
    "    \n",
    "    # Calculate metrics on original scale\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_actual, y_pred))\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "    \n",
    "    print(\"\\nMetrics on Original Scale (Crores):\")\n",
    "    print(f\"  MAE:  {mae:.4f} Crores\")\n",
    "    print(f\"  RMSE: {rmse:.4f} Crores\")\n",
    "    print(f\"  RÂ²:   {r2:.4f}\")\n",
    "    \n",
    "    # Percentage errors\n",
    "    mape = np.mean(np.abs((y_actual - y_pred) / y_actual)) * 100\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'mape': mape\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5e1222eb-dd36-4a3c-928a-ad3d69bbf1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_tuning_workflow(X, y_transformed, preprocessor, method='randomized'):\n",
    "    \"\"\"\n",
    "    Complete hyperparameter tuning workflow\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    method : str\n",
    "        'randomized' - Fast, good results (RECOMMENDED)\n",
    "        'grid' - Thorough, slower\n",
    "        'sequential' - Easy to understand, moderate speed\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"ðŸš€\"*35)\n",
    "    print(\"HYPERPARAMETER TUNING WORKFLOW\")\n",
    "    print(\"ðŸš€\"*35 + \"\\n\")\n",
    "    \n",
    "    # Tune both models\n",
    "    if method == 'randomized':\n",
    "        print(\"\\nðŸ“Š METHOD: Randomized Search (Fast & Effective)\")\n",
    "        xgb_model, xgb_params = tune_xgboost_randomized(X, y_transformed, preprocessor, n_iter=50)\n",
    "        lgb_model, lgb_params = tune_lightgbm_randomized(X, y_transformed, preprocessor, n_iter=50)\n",
    "        \n",
    "   \n",
    "        \n",
    "    \n",
    "    \n",
    "    # Evaluate XGBoost\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EVALUATING TUNED XGBOOST\")\n",
    "    xgb_metrics = evaluate_final_model(xgb_model, X, y_transformed)\n",
    "    \n",
    "    # Evaluate LightGBM if tuned\n",
    "    if lgb_model is not None:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"EVALUATING TUNED LIGHTGBM\")\n",
    "        lgb_metrics = evaluate_final_model(lgb_model, X, y_transformed)\n",
    "        \n",
    "        # Compare models\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"MODEL COMPARISON\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\nXGBoost  MAE: {xgb_metrics['mae']:.4f}\")\n",
    "        print(f\"LightGBM MAE: {lgb_metrics['mae']:.4f}\")\n",
    "        \n",
    "        if xgb_metrics['mae'] < lgb_metrics['mae']:\n",
    "            print(\"\\nðŸ† WINNER: XGBoost\")\n",
    "            best_model = xgb_model\n",
    "        else:\n",
    "            print(\"\\nðŸ† WINNER: LightGBM\")\n",
    "            best_model = lgb_model\n",
    "    else:\n",
    "        best_model = xgb_model\n",
    "    \n",
    "    return best_model, xgb_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66ed85e4-c4c5-4377-92b0-6831fc2976f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "177b69dc-27a8-4032-b847-18379c005727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€\n",
      "HYPERPARAMETER TUNING WORKFLOW\n",
      "ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€ðŸš€\n",
      "\n",
      "\n",
      "ðŸ“Š METHOD: Randomized Search (Fast & Effective)\n",
      "======================================================================\n",
      "TUNING XGBOOST - Randomized Search\n",
      "======================================================================\n",
      "\n",
      "Testing 50 random parameter combinations...\n",
      "This will take approximately 5-15 minutes...\n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "======================================================================\n",
      "XGBOOST TUNING RESULTS\n",
      "======================================================================\n",
      "\n",
      "Best Score (MAE): 0.1629\n",
      "\n",
      "Best Parameters:\n",
      "  colsample_bytree: 0.7509036332911904\n",
      "  gamma: 0.019481566155116814\n",
      "  learning_rate: 0.18929362645798892\n",
      "  max_depth: 9\n",
      "  min_child_weight: 1\n",
      "  n_estimators: 139\n",
      "  reg_alpha: 0.3189756302937613\n",
      "  reg_lambda: 0.8448753109694546\n",
      "  subsample: 0.6093087742943303\n",
      "\n",
      "Top 5 Configurations:\n",
      " mean_test_mae  std_test_score  mean_fit_time                                                                                                                                                                                                                                                                                                                                                                           params\n",
      "      0.162927        0.038346       5.526502 {'regressor__colsample_bytree': 0.7509036332911904, 'regressor__gamma': 0.019481566155116814, 'regressor__learning_rate': 0.18929362645798892, 'regressor__max_depth': 9, 'regressor__min_child_weight': 1, 'regressor__n_estimators': 139, 'regressor__reg_alpha': 0.3189756302937613, 'regressor__reg_lambda': 0.8448753109694546, 'regressor__subsample': 0.6093087742943303}\n",
      "      0.164327        0.034703       4.284698 {'regressor__colsample_bytree': 0.7128138290285226, 'regressor__gamma': 0.08871977188986141, 'regressor__learning_rate': 0.22767827797584891, 'regressor__max_depth': 5, 'regressor__min_child_weight': 1, 'regressor__n_estimators': 148, 'regressor__reg_alpha': 0.4126176769114265, 'regressor__reg_lambda': 0.37201808579278317, 'regressor__subsample': 0.9105651842967988}\n",
      "      0.164830        0.034782       5.393085  {'regressor__colsample_bytree': 0.9942601816442402, 'regressor__gamma': 0.1210276357557502, 'regressor__learning_rate': 0.20491930874770478, 'regressor__max_depth': 5, 'regressor__min_child_weight': 8, 'regressor__n_estimators': 172, 'regressor__reg_alpha': 0.24215993827742588, 'regressor__reg_lambda': 0.8031397563798959, 'regressor__subsample': 0.7881202537784153}\n",
      "      0.165007        0.034030       4.247414 {'regressor__colsample_bytree': 0.8858380416719809, 'regressor__gamma': 0.020533758383937895, 'regressor__learning_rate': 0.1256580614189904, 'regressor__max_depth': 5, 'regressor__min_child_weight': 7, 'regressor__n_estimators': 139, 'regressor__reg_alpha': 0.02535074341545751, 'regressor__reg_lambda': 0.9626484146779251, 'regressor__subsample': 0.9343920482048823}\n",
      "      0.165138        0.035592       4.185151  {'regressor__colsample_bytree': 0.6341389859975072, 'regressor__gamma': 0.02584086058430385, 'regressor__learning_rate': 0.1640928431547629, 'regressor__max_depth': 9, 'regressor__min_child_weight': 3, 'regressor__n_estimators': 104, 'regressor__reg_alpha': 0.13835309241780136, 'regressor__reg_lambda': 0.1327454222429698, 'regressor__subsample': 0.9878147468456636}\n",
      "======================================================================\n",
      "TUNING LIGHTGBM - Randomized Search\n",
      "======================================================================\n",
      "\n",
      "Testing 50 random parameter combinations...\n",
      "This will take approximately 3-10 minutes...\n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "======================================================================\n",
      "LIGHTGBM TUNING RESULTS\n",
      "======================================================================\n",
      "\n",
      "Best Score (MAE): 0.1636\n",
      "\n",
      "Best Parameters:\n",
      "  colsample_bytree: 0.9265727492877536\n",
      "  learning_rate: 0.24152008624551982\n",
      "  max_depth: 11\n",
      "  min_child_samples: 15\n",
      "  n_estimators: 142\n",
      "  num_leaves: 22\n",
      "  reg_alpha: 0.5908929431882418\n",
      "  reg_lambda: 0.6775643618422824\n",
      "  subsample: 0.6066351315711425\n",
      "\n",
      "======================================================================\n",
      "EVALUATING TUNED XGBOOST\n",
      "\n",
      "======================================================================\n",
      "FINAL MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Cross-Validation Results (10-fold):\n",
      "  RÂ² Score:  0.7999 Â± 0.1052\n",
      "  MAE:       0.1586 Â± 0.0377\n",
      "\n",
      "Metrics on Original Scale (Crores):\n",
      "  MAE:  0.7174 Crores\n",
      "  RMSE: 1.8567 Crores\n",
      "  RÂ²:   0.6393\n",
      "  MAPE: 30.23%\n",
      "\n",
      "======================================================================\n",
      "EVALUATING TUNED LIGHTGBM\n",
      "\n",
      "======================================================================\n",
      "FINAL MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Cross-Validation Results (10-fold):\n",
      "  RÂ² Score:  0.8077 Â± 0.0965\n",
      "  MAE:       0.1574 Â± 0.0347\n",
      "\n",
      "Metrics on Original Scale (Crores):\n",
      "  MAE:  0.7045 Crores\n",
      "  RMSE: 1.8189 Crores\n",
      "  RÂ²:   0.6538\n",
      "  MAPE: 30.13%\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "XGBoost  MAE: 0.7174\n",
      "LightGBM MAE: 0.7045\n",
      "\n",
      "ðŸ† WINNER: LightGBM\n"
     ]
    }
   ],
   "source": [
    "best_model, best_params = complete_tuning_workflow(\n",
    "    X, y_transformed, preprocessor, \n",
    "    method='randomized'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60efe05b-5398-441e-94d4-542ccb2c3ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pipeline saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save trained pipeline\n",
    "with open(\"lightgbm_price_pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(\"âœ… Pipeline saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44265852-b666-4022-9ed5-ea67bcca0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df.pkl', 'wb') as file:\n",
    "    pickle.dump(X, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6b76a7a-a2f6-405a-85b2-708437411249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_type</th>\n",
       "      <th>sector</th>\n",
       "      <th>bedRoom</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>balcony</th>\n",
       "      <th>agePossession</th>\n",
       "      <th>built_up_area</th>\n",
       "      <th>servant room</th>\n",
       "      <th>store room</th>\n",
       "      <th>furnishing_type</th>\n",
       "      <th>luxury_category</th>\n",
       "      <th>floor_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house</td>\n",
       "      <td>sector 102</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3+</td>\n",
       "      <td>New Property</td>\n",
       "      <td>2750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low Floor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  property_type      sector  bedRoom  bathroom balcony agePossession  \\\n",
       "0         house  sector 102        4         3      3+  New Property   \n",
       "\n",
       "   built_up_area  servant room  store room furnishing_type luxury_category  \\\n",
       "0           2750             0           0     unfurnished             Low   \n",
       "\n",
       "  floor_category  \n",
       "0      Low Floor  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['house', 'sector 102', 4, 3, '3+', 'New Property', 2750, 0, 0, 'unfurnished', 'Low', 'Low Floor']]\n",
    "columns = ['property_type', 'sector', 'bedRoom', 'bathroom', 'balcony',\n",
    "       'agePossession', 'built_up_area', 'servant room', 'store room',\n",
    "       'furnishing_type', 'luxury_category', 'floor_category']\n",
    "\n",
    "# Convert to DataFrame\n",
    "one_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "one_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4631dddc-668a-42bb-895d-b5121ba47b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.05271557])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(best_model.predict(one_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3990e6fb-aa4e-4721-8750-4d11b3fc0458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(X['sector'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e640e93b-e557-4f9e-80b3-68c336f0015d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_type</th>\n",
       "      <th>sector</th>\n",
       "      <th>bedRoom</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>balcony</th>\n",
       "      <th>agePossession</th>\n",
       "      <th>built_up_area</th>\n",
       "      <th>servant room</th>\n",
       "      <th>store room</th>\n",
       "      <th>furnishing_type</th>\n",
       "      <th>luxury_category</th>\n",
       "      <th>floor_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3094.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unfurnished</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      property_type  sector  bedRoom  bathroom  balcony  agePossession  \\\n",
       "247             0.0     0.0        3         3      2.0            4.0   \n",
       "685             0.0     0.0        3         3      4.0            4.0   \n",
       "1661            0.0     0.0        3         3      2.0            4.0   \n",
       "1822            0.0     0.0        3         3      3.0            1.0   \n",
       "2236            0.0     0.0        3         3      3.0            1.0   \n",
       "3137            1.0     0.0        5         5      4.0            1.0   \n",
       "3196            0.0     0.0        3         3      0.0            4.0   \n",
       "3464            0.0     0.0        3         4      3.0            4.0   \n",
       "\n",
       "      built_up_area  servant room  store room furnishing_type  \\\n",
       "247          1267.0             0           0     unfurnished   \n",
       "685          1940.0             1           0     unfurnished   \n",
       "1661         1303.0             0           0     unfurnished   \n",
       "1822         1529.0             0           0     unfurnished   \n",
       "2236         1357.0             0           0     unfurnished   \n",
       "3137          600.0             0           0     unfurnished   \n",
       "3196         1758.0             0           0     unfurnished   \n",
       "3464         3094.0             0           0     unfurnished   \n",
       "\n",
       "      luxury_category  floor_category  \n",
       "247               1.0             2.0  \n",
       "685               1.0             2.0  \n",
       "1661              1.0             2.0  \n",
       "1822              1.0             1.0  \n",
       "2236              1.0             2.0  \n",
       "3137              1.0             2.0  \n",
       "3196              1.0             1.0  \n",
       "3464              1.0             2.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X['sector']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7ecd12a-caa5-4a63-9e3f-631ab4cea537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6049 entries, 0 to 6048\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   property_type    6049 non-null   object \n",
      " 1   sector           6049 non-null   object \n",
      " 2   bedRoom          6049 non-null   int64  \n",
      " 3   bathroom         6049 non-null   int64  \n",
      " 4   balcony          6049 non-null   object \n",
      " 5   agePossession    6049 non-null   object \n",
      " 6   built_up_area    6049 non-null   float64\n",
      " 7   servant room     6049 non-null   int64  \n",
      " 8   store room       6049 non-null   int64  \n",
      " 9   furnishing_type  6049 non-null   object \n",
      " 10  luxury_category  6049 non-null   object \n",
      " 11  floor_category   6049 non-null   object \n",
      "dtypes: float64(1), int64(4), object(7)\n",
      "memory usage: 567.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afd8ad-6827-479f-89da-c8295fabfc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
